{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b940528-6ef1-4ba3-bc95-80194c0e478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "007a1ef9-4ff3-4628-843e-8257ed544178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable mixed precision training\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a239f6a-033d-4e3c-ac69-57b6fcd02ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU detected. Mixed precision training will not be effective on CPU.\n"
     ]
    }
   ],
   "source": [
    "# Check for mixed precision support\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    gpu_device = physical_devices[0]\n",
    "    # Mixed precision support is checked by default by TensorFlow\n",
    "    print(\"Mixed precision training assumed to be supported if GPU supports it. Ensure compatible TensorFlow version.\")\n",
    "else:\n",
    "    print(\"No GPU detected. Mixed precision training will not be effective on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f1896f-b3a2-490d-88e8-6b632252c3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = pd.read_csv('Processed_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb9b443b-0f79-4fec-9c24-9812bdcaf02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "if data.isnull().sum().any():\n",
    "    print(\"Dataset contains missing values. Applying imputation.\")\n",
    "    data.fillna(data.mean(), inplace=True)  # Simple mean imputation; adjust as needed for your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c92eeb3c-62cb-4583-89af-f49c1fe2bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train, X_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_val_normalized = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3251430-b778-4425-8923-566bf2a189f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dimensions\n",
    "input_dim = X_train_normalized.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82f220a7-862b-4e79-9055-afd75f070734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available. Falling back to CPU.\n"
     ]
    }
   ],
   "source": [
    "# GPU setup\n",
    "if physical_devices:\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            physical_devices[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=10240)]  # Set memory limit in MB if needed\n",
    "        )\n",
    "        print(\"GPU is available and will be used.\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error configuring GPU memory:\", e)\n",
    "else:\n",
    "    print(\"GPU not available. Falling back to CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d6d99c4-c2b8-4e11-80e5-889b6ab4fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the autoencoder model\n",
    "def create_autoencoder(encoding_dim=16):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(input_layer)\n",
    "    encoded = Dropout(0.2)(encoded)\n",
    "    encoded = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(encoded)\n",
    "    encoded = Dense(encoding_dim, activation='relu', kernel_regularizer=l2(0.001))(encoded)\n",
    "\n",
    "    decoded = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(encoded)\n",
    "    decoded = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(decoded)\n",
    "    decoded = Dense(input_dim, activation='sigmoid', kernel_regularizer=l2(0.001))(decoded)\n",
    "\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c2e0429-e0e2-4dea-b078-7018055a7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize autoencoder\n",
    "autoencoder = create_autoencoder(encoding_dim=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b08c646d-1b29-483a-a304-659ad0df348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6426394f-00ce-4c2b-86f3-77595e731a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "class LoggingLearningRateCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr = tf.keras.backend.get_value(self.model.optimizer.learning_rate)\n",
    "        print(f\"Epoch {epoch + 1}: Learning rate is {lr}\")\n",
    "\n",
    "logging_lr_callback = LoggingLearningRateCallback()\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='best_autoencoder.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c57769b-6a64-4ffc-9377-15225dbbec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimized data pipeline\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_normalized, X_train_normalized))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=2048).batch(256).prefetch(tf.data.AUTOTUNE)  # Adjusted buffer size and batch size\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_normalized, X_val_normalized)).batch(256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a1bc0df-0b3e-4d86-959f-6149aab158e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2176\n",
      "Epoch 1: val_loss improved from inf to 0.93668, saving model to best_autoencoder.keras\n",
      "Epoch 1: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - loss: 1.2156 - val_loss: 0.9367 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.9242\n",
      "Epoch 2: val_loss improved from 0.93668 to 0.91879, saving model to best_autoencoder.keras\n",
      "Epoch 2: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.9241 - val_loss: 0.9188 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.9098\n",
      "Epoch 3: val_loss improved from 0.91879 to 0.91051, saving model to best_autoencoder.keras\n",
      "Epoch 3: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.9098 - val_loss: 0.9105 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.9015\n",
      "Epoch 4: val_loss improved from 0.91051 to 0.90496, saving model to best_autoencoder.keras\n",
      "Epoch 4: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.9014 - val_loss: 0.9050 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8981\n",
      "Epoch 5: val_loss improved from 0.90496 to 0.90024, saving model to best_autoencoder.keras\n",
      "Epoch 5: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8980 - val_loss: 0.9002 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8929\n",
      "Epoch 6: val_loss improved from 0.90024 to 0.89915, saving model to best_autoencoder.keras\n",
      "Epoch 6: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8929 - val_loss: 0.8991 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8913\n",
      "Epoch 7: val_loss improved from 0.89915 to 0.89837, saving model to best_autoencoder.keras\n",
      "Epoch 7: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8913 - val_loss: 0.8984 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m309/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8898\n",
      "Epoch 8: val_loss improved from 0.89837 to 0.89734, saving model to best_autoencoder.keras\n",
      "Epoch 8: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.8898 - val_loss: 0.8973 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8912\n",
      "Epoch 9: val_loss improved from 0.89734 to 0.89678, saving model to best_autoencoder.keras\n",
      "Epoch 9: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8911 - val_loss: 0.8968 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8910\n",
      "Epoch 10: val_loss improved from 0.89678 to 0.89449, saving model to best_autoencoder.keras\n",
      "Epoch 10: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8910 - val_loss: 0.8945 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8846\n",
      "Epoch 11: val_loss improved from 0.89449 to 0.89308, saving model to best_autoencoder.keras\n",
      "Epoch 11: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.8846 - val_loss: 0.8931 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8853\n",
      "Epoch 12: val_loss improved from 0.89308 to 0.89231, saving model to best_autoencoder.keras\n",
      "Epoch 12: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8852 - val_loss: 0.8923 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8840\n",
      "Epoch 13: val_loss improved from 0.89231 to 0.89080, saving model to best_autoencoder.keras\n",
      "Epoch 13: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8839 - val_loss: 0.8908 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8829\n",
      "Epoch 14: val_loss improved from 0.89080 to 0.89014, saving model to best_autoencoder.keras\n",
      "Epoch 14: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.8829 - val_loss: 0.8901 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8840\n",
      "Epoch 15: val_loss improved from 0.89014 to 0.88899, saving model to best_autoencoder.keras\n",
      "Epoch 15: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8839 - val_loss: 0.8890 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8842\n",
      "Epoch 16: val_loss did not improve from 0.88899\n",
      "Epoch 16: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8841 - val_loss: 0.8892 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8808\n",
      "Epoch 17: val_loss improved from 0.88899 to 0.88826, saving model to best_autoencoder.keras\n",
      "Epoch 17: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8807 - val_loss: 0.8883 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8813\n",
      "Epoch 18: val_loss improved from 0.88826 to 0.88798, saving model to best_autoencoder.keras\n",
      "Epoch 18: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8813 - val_loss: 0.8880 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8804\n",
      "Epoch 19: val_loss improved from 0.88798 to 0.88726, saving model to best_autoencoder.keras\n",
      "Epoch 19: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8803 - val_loss: 0.8873 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8787\n",
      "Epoch 20: val_loss improved from 0.88726 to 0.88682, saving model to best_autoencoder.keras\n",
      "Epoch 20: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8786 - val_loss: 0.8868 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8821\n",
      "Epoch 21: val_loss improved from 0.88682 to 0.88665, saving model to best_autoencoder.keras\n",
      "Epoch 21: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8820 - val_loss: 0.8866 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8827\n",
      "Epoch 22: val_loss improved from 0.88665 to 0.88650, saving model to best_autoencoder.keras\n",
      "Epoch 22: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8826 - val_loss: 0.8865 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8816\n",
      "Epoch 23: val_loss improved from 0.88650 to 0.88611, saving model to best_autoencoder.keras\n",
      "Epoch 23: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8816 - val_loss: 0.8861 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8805\n",
      "Epoch 24: val_loss did not improve from 0.88611\n",
      "Epoch 24: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8805 - val_loss: 0.8861 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8812\n",
      "Epoch 25: val_loss did not improve from 0.88611\n",
      "Epoch 25: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8812 - val_loss: 0.8863 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8796\n",
      "Epoch 26: val_loss improved from 0.88611 to 0.88554, saving model to best_autoencoder.keras\n",
      "Epoch 26: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8796 - val_loss: 0.8855 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8829\n",
      "Epoch 27: val_loss did not improve from 0.88554\n",
      "Epoch 27: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8829 - val_loss: 0.8860 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8801\n",
      "Epoch 28: val_loss did not improve from 0.88554\n",
      "Epoch 28: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8800 - val_loss: 0.8858 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8776\n",
      "Epoch 29: val_loss improved from 0.88554 to 0.88541, saving model to best_autoencoder.keras\n",
      "Epoch 29: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8775 - val_loss: 0.8854 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8791\n",
      "Epoch 30: val_loss improved from 0.88541 to 0.88530, saving model to best_autoencoder.keras\n",
      "Epoch 30: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8790 - val_loss: 0.8853 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8778\n",
      "Epoch 31: val_loss improved from 0.88530 to 0.88508, saving model to best_autoencoder.keras\n",
      "Epoch 31: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8778 - val_loss: 0.8851 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8802\n",
      "Epoch 32: val_loss improved from 0.88508 to 0.88475, saving model to best_autoencoder.keras\n",
      "Epoch 32: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.8801 - val_loss: 0.8848 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8775\n",
      "Epoch 33: val_loss did not improve from 0.88475\n",
      "Epoch 33: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 0.8775 - val_loss: 0.8848 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8804\n",
      "Epoch 34: val_loss improved from 0.88475 to 0.88449, saving model to best_autoencoder.keras\n",
      "Epoch 34: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8803 - val_loss: 0.8845 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.8797\n",
      "Epoch 35: val_loss did not improve from 0.88449\n",
      "Epoch 35: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.8797 - val_loss: 0.8850 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8772\n",
      "Epoch 36: val_loss improved from 0.88449 to 0.88242, saving model to best_autoencoder.keras\n",
      "Epoch 36: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - loss: 0.8772 - val_loss: 0.8824 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8736\n",
      "Epoch 37: val_loss improved from 0.88242 to 0.88092, saving model to best_autoencoder.keras\n",
      "Epoch 37: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8736 - val_loss: 0.8809 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8735\n",
      "Epoch 38: val_loss improved from 0.88092 to 0.88048, saving model to best_autoencoder.keras\n",
      "Epoch 38: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - loss: 0.8735 - val_loss: 0.8805 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8734\n",
      "Epoch 39: val_loss did not improve from 0.88048\n",
      "Epoch 39: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8733 - val_loss: 0.8806 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8737\n",
      "Epoch 40: val_loss improved from 0.88048 to 0.87985, saving model to best_autoencoder.keras\n",
      "Epoch 40: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8736 - val_loss: 0.8799 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8724\n",
      "Epoch 41: val_loss did not improve from 0.87985\n",
      "Epoch 41: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.8724 - val_loss: 0.8800 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8743\n",
      "Epoch 42: val_loss did not improve from 0.87985\n",
      "Epoch 42: Learning rate is 0.0010000000474974513\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8742 - val_loss: 0.8799 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8729\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.87985\n",
      "Epoch 43: Learning rate is 0.0005000000237487257\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.8729 - val_loss: 0.8804 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8748\n",
      "Epoch 44: val_loss improved from 0.87985 to 0.87957, saving model to best_autoencoder.keras\n",
      "Epoch 44: Learning rate is 0.0005000000237487257\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.8747 - val_loss: 0.8796 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8701\n",
      "Epoch 45: val_loss improved from 0.87957 to 0.87910, saving model to best_autoencoder.keras\n",
      "Epoch 45: Learning rate is 0.0005000000237487257\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8701 - val_loss: 0.8791 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8722\n",
      "Epoch 46: val_loss did not improve from 0.87910\n",
      "Epoch 46: Learning rate is 0.0005000000237487257\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8722 - val_loss: 0.8791 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8762\n",
      "Epoch 47: val_loss improved from 0.87910 to 0.87896, saving model to best_autoencoder.keras\n",
      "Epoch 47: Learning rate is 0.0005000000237487257\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.8761 - val_loss: 0.8790 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8745\n",
      "Epoch 48: val_loss did not improve from 0.87896\n",
      "Epoch 48: Learning rate is 0.0005000000237487257\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8744 - val_loss: 0.8791 - learning_rate: 5.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8715\n",
      "Epoch 49: val_loss did not improve from 0.87896\n",
      "Epoch 49: Learning rate is 0.0005000000237487257\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8715 - val_loss: 0.8791 - learning_rate: 5.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8765\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.87896\n",
      "Epoch 50: Learning rate is 0.0002500000118743628\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8765 - val_loss: 0.8791 - learning_rate: 5.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8729\n",
      "Epoch 51: val_loss improved from 0.87896 to 0.87883, saving model to best_autoencoder.keras\n",
      "Epoch 51: Learning rate is 0.0002500000118743628\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8729 - val_loss: 0.8788 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8679\n",
      "Epoch 52: val_loss improved from 0.87883 to 0.87860, saving model to best_autoencoder.keras\n",
      "Epoch 52: Learning rate is 0.0002500000118743628\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8679 - val_loss: 0.8786 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8724\n",
      "Epoch 53: val_loss did not improve from 0.87860\n",
      "Epoch 53: Learning rate is 0.0002500000118743628\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8724 - val_loss: 0.8788 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8741\n",
      "Epoch 54: val_loss improved from 0.87860 to 0.87856, saving model to best_autoencoder.keras\n",
      "Epoch 54: Learning rate is 0.0002500000118743628\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8741 - val_loss: 0.8786 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8752\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.87856\n",
      "Epoch 55: Learning rate is 0.0001250000059371814\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8751 - val_loss: 0.8787 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8758\n",
      "Epoch 56: val_loss improved from 0.87856 to 0.87847, saving model to best_autoencoder.keras\n",
      "Epoch 56: Learning rate is 0.0001250000059371814\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8757 - val_loss: 0.8785 - learning_rate: 1.2500e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8723\n",
      "Epoch 57: val_loss did not improve from 0.87847\n",
      "Epoch 57: Learning rate is 0.0001250000059371814\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.8723 - val_loss: 0.8785 - learning_rate: 1.2500e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8689\n",
      "Epoch 58: val_loss improved from 0.87847 to 0.87845, saving model to best_autoencoder.keras\n",
      "Epoch 58: Learning rate is 0.0001250000059371814\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.8689 - val_loss: 0.8784 - learning_rate: 1.2500e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8721\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.87845\n",
      "Epoch 59: Learning rate is 6.25000029685907e-05\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8720 - val_loss: 0.8785 - learning_rate: 1.2500e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8746\n",
      "Epoch 60: val_loss improved from 0.87845 to 0.87833, saving model to best_autoencoder.keras\n",
      "Epoch 60: Learning rate is 6.25000029685907e-05\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.8746 - val_loss: 0.8783 - learning_rate: 6.2500e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8748\n",
      "Epoch 61: val_loss did not improve from 0.87833\n",
      "Epoch 61: Learning rate is 6.25000029685907e-05\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8747 - val_loss: 0.8783 - learning_rate: 6.2500e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.8723\n",
      "Epoch 62: val_loss did not improve from 0.87833\n",
      "Epoch 62: Learning rate is 6.25000029685907e-05\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.8723 - val_loss: 0.8784 - learning_rate: 6.2500e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8716\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 63: val_loss improved from 0.87833 to 0.87829, saving model to best_autoencoder.keras\n",
      "Epoch 63: Learning rate is 3.125000148429535e-05\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8715 - val_loss: 0.8783 - learning_rate: 6.2500e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8743\n",
      "Epoch 64: val_loss improved from 0.87829 to 0.87827, saving model to best_autoencoder.keras\n",
      "Epoch 64: Learning rate is 3.125000148429535e-05\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.8743 - val_loss: 0.8783 - learning_rate: 3.1250e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8717\n",
      "Epoch 65: val_loss improved from 0.87827 to 0.87827, saving model to best_autoencoder.keras\n",
      "Epoch 65: Learning rate is 3.125000148429535e-05\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.8717 - val_loss: 0.8783 - learning_rate: 3.1250e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8702\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 66: val_loss improved from 0.87827 to 0.87824, saving model to best_autoencoder.keras\n",
      "Epoch 66: Learning rate is 1.5625000742147677e-05\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.8702 - val_loss: 0.8782 - learning_rate: 3.1250e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8724\n",
      "Epoch 67: val_loss improved from 0.87824 to 0.87824, saving model to best_autoencoder.keras\n",
      "Epoch 67: Learning rate is 1.5625000742147677e-05\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8724 - val_loss: 0.8782 - learning_rate: 1.5625e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8720\n",
      "Epoch 68: val_loss did not improve from 0.87824\n",
      "Epoch 68: Learning rate is 1.5625000742147677e-05\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8719 - val_loss: 0.8783 - learning_rate: 1.5625e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8726\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 69: val_loss improved from 0.87824 to 0.87824, saving model to best_autoencoder.keras\n",
      "Epoch 69: Learning rate is 7.812500371073838e-06\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8725 - val_loss: 0.8782 - learning_rate: 1.5625e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8733\n",
      "Epoch 70: val_loss did not improve from 0.87824\n",
      "Epoch 70: Learning rate is 7.812500371073838e-06\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8733 - val_loss: 0.8782 - learning_rate: 7.8125e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8735\n",
      "Epoch 71: val_loss did not improve from 0.87824\n",
      "Epoch 71: Learning rate is 7.812500371073838e-06\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8735 - val_loss: 0.8782 - learning_rate: 7.8125e-06\n",
      "Epoch 72/100\n",
      "\u001b[1m311/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8724\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 72: val_loss improved from 0.87824 to 0.87823, saving model to best_autoencoder.keras\n",
      "Epoch 72: Learning rate is 3.906250185536919e-06\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8723 - val_loss: 0.8782 - learning_rate: 7.8125e-06\n",
      "Epoch 73/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8707\n",
      "Epoch 73: val_loss improved from 0.87823 to 0.87823, saving model to best_autoencoder.keras\n",
      "Epoch 73: Learning rate is 3.906250185536919e-06\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - loss: 0.8706 - val_loss: 0.8782 - learning_rate: 3.9063e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8715\n",
      "Epoch 74: val_loss did not improve from 0.87823\n",
      "Epoch 74: Learning rate is 3.906250185536919e-06\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8714 - val_loss: 0.8782 - learning_rate: 3.9063e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8724\n",
      "Epoch 75: val_loss improved from 0.87823 to 0.87823, saving model to best_autoencoder.keras\n",
      "Epoch 75: Learning rate is 3.906250185536919e-06\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8723 - val_loss: 0.8782 - learning_rate: 3.9063e-06\n",
      "Epoch 76/100\n",
      "\u001b[1m310/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8703\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.87823\n",
      "Epoch 76: Learning rate is 1.9531250927684596e-06\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.8703 - val_loss: 0.8782 - learning_rate: 3.9063e-06\n",
      "Epoch 77/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8726\n",
      "Epoch 77: val_loss did not improve from 0.87823\n",
      "Epoch 77: Learning rate is 1.9531250927684596e-06\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.8725 - val_loss: 0.8782 - learning_rate: 1.9531e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8706\n",
      "Epoch 78: val_loss did not improve from 0.87823\n",
      "Epoch 78: Learning rate is 1.9531250927684596e-06\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.8706 - val_loss: 0.8782 - learning_rate: 1.9531e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8729\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.87823\n",
      "Epoch 79: Learning rate is 9.999999974752427e-07\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.8728 - val_loss: 0.8782 - learning_rate: 1.9531e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.8710\n",
      "Epoch 80: val_loss did not improve from 0.87823\n",
      "Epoch 80: Learning rate is 9.999999974752427e-07\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.8710 - val_loss: 0.8782 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = autoencoder.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint, logging_lr_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ae49da2-cce8-4b62-94ed-18cb7be74607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract loss values\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfacf9f6-3c05-433c-b209-5707a8fb13c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Squared Error (Loss)')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e4791f-c5d0-4abf-adbb-398ed052a2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
